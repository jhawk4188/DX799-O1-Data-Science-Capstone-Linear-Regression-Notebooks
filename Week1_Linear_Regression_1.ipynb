{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ac5a0cf",
   "metadata": {},
   "source": [
    "# Week 1  Linear Regression part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b4d739",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Paths to uploaded datasets\n",
    "DATA_SMALL = \"/mnt/data/T_ONTIME_REPORTING.csv\"\n",
    "DATA_LARGE = \"/mnt/data/DelayData.csv\"\n",
    "\n",
    "# Utility: fast preview of a CSV\n",
    "def fast_preview(path, n=5):\n",
    "    print(f\"Previewing {path}\")\n",
    "    df = pd.read_csv(path, nrows=n)\n",
    "    display(df.head(n))\n",
    "    return df\n",
    "\n",
    "# Utility: chunked iterator for large CSV\n",
    "def chunk_reader(path, chunksize=100_000, usecols=None, dtype=None):\n",
    "    return pd.read_csv(path, chunksize=chunksize, usecols=usecols, dtype=dtype)\n",
    "\n",
    "# Utility: downsample large dataset for experiments\n",
    "def load_sample_from_large(n_rows=200_000, usecols=None):\n",
    "    # Stream chunks until we accumulate n_rows\n",
    "    rows = []\n",
    "    total = 0\n",
    "    for chunk in chunk_reader(DATA_LARGE, chunksize=100_000, usecols=usecols):\n",
    "        rows.append(chunk)\n",
    "        total += len(chunk)\n",
    "        if total >= n_rows:\n",
    "            break\n",
    "    df = pd.concat(rows, ignore_index=True)\n",
    "    print(f\"Loaded sample of {len(df):,} rows from large file\")\n",
    "    return df\n",
    "\n",
    "# Quick sanity check previews\n",
    "_ = fast_preview(DATA_SMALL, n=5)\n",
    "_ = fast_preview(DATA_LARGE, n=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202f6452",
   "metadata": {},
   "source": [
    "## Goal\n",
    "Fit linear models with polynomial and interaction terms. Diagnose multicollinearity and VIF.\n",
    "Use the uploaded flight data to predict arrival delay as a continuous target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacfa85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select columns for a regression experiment\n",
    "usecols = [\n",
    "    \"arrdelay\",\"depdelay\",\"scheduledhour\",\"month\",\"dayofmonth\",\n",
    "    \"temperature\",\"windspeed\",\"raindummy\",\"snowdummy\",\n",
    "    \"marketshareorigin\",\"marketsharedest\"\n",
    "]\n",
    "\n",
    "df = load_sample_from_large(n_rows=250_000, usecols=usecols).dropna()\n",
    "\n",
    "# Basic EDA\n",
    "df.describe(include=\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7109b0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature engineering  polynomial and interaction terms\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y = df[\"arrdelay\"]\n",
    "X = df.drop(columns=[\"arrdelay\"])\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "pred = linreg.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, pred, squared=False)\n",
    "r2 = r2_score(y_test, pred)\n",
    "\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2:\", r2)\n",
    "print(\"Num features after polynomial transform:\", X_poly.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d6a569",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Multicollinearity and VIF on a modest subset\n",
    "import pandas as pd\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X_small = df[[\"depdelay\",\"scheduledhour\",\"month\",\"dayofmonth\",\"temperature\",\"windspeed\"]].copy()\n",
    "X_small = sm.add_constant(X_small)\n",
    "vif = pd.Series([variance_inflation_factor(X_small.values, i) for i in range(X_small.shape[1])],\n",
    "                index=X_small.columns, name=\"VIF\")\n",
    "vif\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6060bad",
   "metadata": {},
   "source": [
    "### Notes to include in Milestone One\n",
    "* Overfitting avoidance  holdout set and limit polynomial degree to two\n",
    "* Metrics  RMSE and R2\n",
    "* Expected and unexpected  strong effect of departure delay on arrival delay  weather weaker than expected"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
